{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HECxh4B3lKBR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from methods import DID_TWFE, SC_TWFE, DIFP_TWFE, TROP_TWFE_average, SDID_weights, SDID_TWFE\n",
    "from utils import one_simulation\n",
    "import pickle\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EODKjnPNQ1L6"
   },
   "source": [
    "## Load covariates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covariates = ['charge_violent', 'charge_dui', 'charge_drug', 'charge_traffic', 'age', 'male', 'black','num_charges','ada','adr']\n",
    "covariates = ['proportion_violent', 'proportion_dui_offense', 'proportion_criminal_traffic', 'age_mean', 'proportion_male', 'proportion_black', 'num_charges_mean', 'ada', 'adr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_arrays = []\n",
    "for covariate in covariates:\n",
    "    df = pd.read_csv('FL-covariates/'+covariate+'.csv')\n",
    "    # if estimating effects for FL, drop GA and move FL to first; vice versa\n",
    "    df = df.drop(['cycle','GA','ME','WV'],axis=1)\n",
    "    column_to_move = 'FL'\n",
    "    columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "    df = df[columns]\n",
    "    df = df.fillna(df.mean(numeric_only=True))\n",
    "    covariates_arrays.append(df.values)\n",
    "covariate_array = np.array(covariates_arrays)\n",
    "T = covariate_array.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals_list = []\n",
    "outcomes_list = []\n",
    "covariates_list = []\n",
    "for i in range(1,19):\n",
    "    horizon = i*28\n",
    "    print(horizon)\n",
    "    \n",
    "    # for fixed-windows select 13 pre-treatment periods plus 3 post-treatment periods\n",
    "    panel_size = 16\n",
    "    \n",
    "    current_covariates = np.copy(covariate_array[:,:panel_size,:])\n",
    "    covariates_list.append(current_covariates)\n",
    "    X = current_covariates.reshape(current_covariates.shape[0], -1).T\n",
    "    \n",
    "    # rebookings\n",
    "#     df = pd.read_csv('FL-rebookings/within_'+str(horizon)+'_days.csv')\n",
    "#     df = df.drop(['cycle','GA','ME','WV'],axis=1)\n",
    "#     column_to_move = 'FL'\n",
    "#     columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "#     df = df[columns]    \n",
    "\n",
    "    # detention\n",
    "    df = pd.read_csv('FL-detentions/proportion_of_next_'+str(horizon)+'_days.csv')\n",
    "    df = df.drop(['cycle','GA','ME','WV'],axis=1)\n",
    "    column_to_move = 'FL'\n",
    "    columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "    df = df[columns] \n",
    "    \n",
    "    # los \n",
    "#     df = pd.read_csv('FL-detentions/cutoff_3_days.csv')\n",
    "#     df = df.drop(['cycle','GA', 'ME','WV'],axis=1)\n",
    "#     column_to_move = 'FL'\n",
    "#     columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "#     df = df[columns]\n",
    "    \n",
    "    outcomes = df.values[:panel_size,:]\n",
    "    outcomes_list.append(outcomes.T)\n",
    "    y = outcomes.flatten()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "    outcome_residuals = residuals.reshape(current_covariates.shape[1],-1).T\n",
    "    residuals_list.append(outcome_residuals)\n",
    "    #np.save('rebooking_residuals/within_'+str(horizon)+'_days.npy', rebooking_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "stds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(outcomes_list[-2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH365AgTQ1L7"
   },
   "outputs": [],
   "source": [
    "month = 1\n",
    "Y_true = residuals_list[month-1]\n",
    "rebookings = outcomes_list[month-1]\n",
    "current_covariates = covariates_list[month-1]\n",
    "N_total,T_total = Y_true.shape\n",
    "W_true = np.zeros((N_total,T_total))\n",
    "W_true[0,13:] = 1\n",
    "Y_control = np.delete(Y_true, 0, axis=0)\n",
    "\n",
    "treated_periods = T_total-13\n",
    "treated_unit_number = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Tuning Parameter for TROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select lambda_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ATE(trial, Y, lambda_unit, lambda_time, lambda_nn):\n",
    "    np.random.seed(trial)\n",
    "    N, T = Y.shape\n",
    "    test_units = np.random.choice(np.arange(N), size=treated_unit_number,replace=False)\n",
    "    W_test = np.zeros(Y.shape)\n",
    "    W_test[test_units,-treated_periods:] = 1\n",
    "    estimate = TROP_TWFE_average(Y,W_test, test_units,lambda_unit=lambda_unit,lambda_time=lambda_time,lambda_nn=lambda_nn,treated_periods=treated_periods)\n",
    "    return estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = []\n",
    "lambda_units = np.arange(0,4,4/20)\n",
    "for lambda_unit in lambda_units:\n",
    "    lambda_time = 0.4\n",
    "    lambda_nn = 0.02\n",
    "    print(lambda_unit,lambda_time,lambda_nn)\n",
    "    ATEs = Parallel(n_jobs=36, prefer='processes')(\n",
    "                 delayed(get_ATE)(trial,Y_control,lambda_unit=lambda_unit,lambda_time=lambda_time,lambda_nn=lambda_nn)\n",
    "                 for trial in range(200))\n",
    "    Q.append(np.sqrt(np.mean(np.square(ATEs))))\n",
    "    print(np.sqrt(np.mean(np.square(ATEs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lambda_units[np.argmin(Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(lambda_units,Q)\n",
    "plt.xlabel('lambda_unit')\n",
    "plt.ylabel('Q value')\n",
    "plt.title('Q function for CPS data using SDID time weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select lambda_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = []\n",
    "lambda_times = np.arange(0,1,1/20)\n",
    "for lambda_time in lambda_times:\n",
    "    lambda_nn = 0.02\n",
    "    lambda_unit = 0.6\n",
    "    print(lambda_unit,lambda_time,lambda_nn)\n",
    "    ATEs = Parallel(n_jobs=36, prefer='processes')(\n",
    "                 delayed(get_ATE)(trial,Y_control,lambda_unit=lambda_unit,lambda_time=lambda_time,lambda_nn=lambda_nn)\n",
    "                 for trial in range(200))\n",
    "    Q.append(np.sqrt(np.mean(np.square(ATEs))))\n",
    "    print(np.sqrt(np.mean(np.square(ATEs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_times[np.argmin(Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lambda_times,Q)\n",
    "plt.xlabel('lambda_time')\n",
    "plt.ylabel('Q value')\n",
    "plt.title('Q function for CPS data using SDID unit weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select lambad_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q = []\n",
    "lambda_nns = np.arange(0.005,0.105,0.1/20)\n",
    "for lambda_nn in lambda_nns:\n",
    "    lambda_time = 0.4\n",
    "    lambda_unit = 0.6\n",
    "    print(lambda_unit,lambda_time,lambda_nn)\n",
    "    ATEs = Parallel(n_jobs=36, prefer='processes')(\n",
    "                 delayed(get_ATE)(trial,Y_control,lambda_unit=lambda_unit,lambda_time=lambda_time,lambda_nn=lambda_nn)\n",
    "                 for trial in range(200))\n",
    "    Q.append(np.sqrt(np.mean(np.square(ATEs))))\n",
    "    print(np.sqrt(np.mean(np.square(ATEs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_nns[np.argmin(Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lambda_nns,Q)\n",
    "plt.xlabel('lambda_nn')\n",
    "plt.ylabel('Q value')\n",
    "plt.title('Q function for CPS data using SDID unit weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FL TROP fixed post-treatment months, recidivism\n",
    "TROP_parameter_dict = {1: [2.6,0.25,0.005], \n",
    "                      2: [8,0.05,0.05],\n",
    "                      3: [2,0.15,0.05],\n",
    "                      4: [1,0.2,0.055],\n",
    "                      5: [10,0.25,0.3],\n",
    "                      6: [10,0.2,0.3],\n",
    "                      7: [4.2,0.25,0.135],\n",
    "                      8: [9,0.225,0.075],\n",
    "                      9: [9,0.175,0.095],\n",
    "                      10: [11,0.175,0.075],\n",
    "                      11: [11,0.175,0.075],\n",
    "                      12: [9,0.25,0.065],\n",
    "                      13: [10,0.25,0.065],\n",
    "                      14: [10,0.225,0.065],\n",
    "                      15: [10,0.15,0.085],\n",
    "                      16: [9,0.15,0.085],\n",
    "                      17: [10,0.15,0.085],\n",
    "                      18: [10,0.15,0.085]}\n",
    "\n",
    "# FL TROP varying post-treatment months, detention\n",
    "TROP_parameter_dict = {1: [0.6,0.4,0.02], \n",
    "                      2: [0,0,0.011],\n",
    "                      3: [0,0,0.011],\n",
    "                      4: [1,0.5,0.011],\n",
    "                      5: [1.8,0.4,0.011],\n",
    "                      6: [0.9,0.4,0.011],\n",
    "                      7: [0.9,0.3,0.021],\n",
    "                      8: [0,0.1,0.006],\n",
    "                      9: [2.4,0.1,0.011],\n",
    "                      10: [0,0.1,0.011],\n",
    "                      11: [0,0.1,0.051],\n",
    "                      12: [0,0,0.081],\n",
    "                      13: [2.8,0,0.081],\n",
    "                      14: [1.2,0,0.041],\n",
    "                      15: [0.8,0,0.021],\n",
    "                      16: [0,0.4,0.021],\n",
    "                      17: [0,0.6,0.011],\n",
    "                      18: [0,0.4,0.011],\n",
    "                      19: [4.8,0.1,0.011]}\n",
    "\n",
    "# FL TROP varying post-treatment months, los\n",
    "# TROP_parameter_dict = {1: [2.4,0.1,0.011], \n",
    "#                       2: [0,0,0.011],\n",
    "#                       3: [0,0.5,0.005],\n",
    "#                       4: [1,0.5,0.011],\n",
    "#                       5: [1.8,0.4,0.011],\n",
    "#                       6: [0.9,0.4,0.011],\n",
    "#                       7: [0.9,0.3,0.021],\n",
    "#                       8: [0,0.1,0.006],\n",
    "#                       9: [2.4,0.1,0.011],\n",
    "#                       10: [0,0.1,0.011],\n",
    "#                       11: [0,0.1,0.051],\n",
    "#                       12: [0,0,0.081],\n",
    "#                       13: [2.8,0,0.081],\n",
    "#                       14: [1.2,0,0.041],\n",
    "#                       15: [0.8,0,0.021],\n",
    "#                       16: [0,0.4,0.021],\n",
    "#                       17: [0,0.6,0.011],\n",
    "#                       18: [0,0.4,0.011],\n",
    "#                       19: [4.8,0.1,0.011]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_treatment_effect(data, TROP_parameters, Y_original, t_treat):\n",
    "    \n",
    "    trop_estimate, sdid_estimate, sc_estimate, did_estimate, mc_estimate, difp_estimate = one_simulation(data, TROP_parameters,t_treat)\n",
    "\n",
    "    did_effect = did_estimate/(np.mean(Y_original[0,-t_treat:])-did_estimate)\n",
    "    sc_effect = sc_estimate/(np.mean(Y_original[0,-t_treat:])-sc_estimate)\n",
    "    mc_effect = mc_estimate/(np.mean(Y_original[0,-t_treat:])-mc_estimate)\n",
    "    sdid_effect = sdid_estimate/(np.mean(Y_original[0,-t_treat:])-sdid_estimate)\n",
    "    trop_effect = trop_estimate/(np.mean(Y_original[0,-t_treat:])-trop_estimate)\n",
    "    \n",
    "    return np.array([did_effect, sc_effect, mc_effect, sdid_effect, trop_effect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "Y_true = residuals_list[month-1]\n",
    "rebookings = outcomes_list[month-1]\n",
    "current_covariates = covariates_list[month-1]\n",
    "N_total,T_total = Y_true.shape\n",
    "W_true = np.zeros((N_total,T_total))\n",
    "W_true[0,13:] = 1\n",
    "Y_control = np.delete(Y_true, 0, axis=0)\n",
    "\n",
    "treated_periods = T_total-13\n",
    "treated_unit_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_units = np.array([0])\n",
    "t_treat = T_total-13\n",
    "\n",
    "#TROP parameters\n",
    "lambda_unit, lambda_time, lambda_nn = TROP_parameter_dict[month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_treatment_effect([Y_true,W_true,np.array([0])], [lambda_unit, lambda_time, lambda_nn], rebookings, t_treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimates.append(compute_treatment_effect([Y_true,W_true,np.array([0])], [lambda_unit, lambda_time, lambda_nn], rebookings, t_treat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(estimates[month-1]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bootstrapped_effect(rebookings, current_covariates, TROP_parameters, t_treat):\n",
    "    N_total, T_total = rebookings.shape\n",
    "    index = np.random.choice(np.arange(N_total-1)+1, size=N_total-1, replace=True)\n",
    "    \n",
    "    bootstrapped_covariates = np.copy(current_covariates)\n",
    "    bootstrapped_covariates[:,:,1:] = current_covariates[:,:,index]\n",
    "\n",
    "    X = bootstrapped_covariates.reshape(bootstrapped_covariates.shape[0], -1).T\n",
    "    \n",
    "    bootstrapped_outcomes = np.copy(rebookings)\n",
    "    bootstrapped_outcomes[1:,:] = rebookings[index,:]\n",
    "    \n",
    "    y = bootstrapped_outcomes.T.flatten()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "    Y_test = residuals.reshape(bootstrapped_covariates.shape[1],-1).T\n",
    "\n",
    "    return compute_treatment_effect([Y_test, W_test, np.array([0])], TROP_parameters, bootstrapped_outcomes, t_treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_bootstrapped_effect(rebookings, Y_true, TROP_parameters, t_treat):\n",
    "    N_total, T_total = rebookings.shape\n",
    "    index = np.random.choice(np.arange(N_total-1)+1, size=N_total-1, replace=True)\n",
    "    \n",
    "    bootstrapped_outcomes = np.copy(rebookings)\n",
    "    bootstrapped_outcomes[1:,:] = rebookings[index,:]\n",
    "\n",
    "    Y_test = np.copy(Y_true)\n",
    "    Y_test[1:,:] = Y_true[index,:]\n",
    "    \n",
    "    W_test = np.copy(W_true)\n",
    "    W_test[1:,:] = W_true[index,:]\n",
    "    \n",
    "    return compute_treatment_effect([Y_test, W_test, np.array([0])], TROP_parameters, bootstrapped_outcomes, t_treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments in parallel\n",
    "num_experiments = 1000\n",
    "num_cores = 36\n",
    "np.random.seed(0)\n",
    "# set n_jobs to the number of cores\n",
    "errors = Parallel(n_jobs=num_cores, prefer='processes')(\n",
    "                 delayed(simple_bootstrapped_effect)(rebookings, Y_true, [lambda_unit, lambda_time, lambda_nn], t_treat)\n",
    "                 for experiment in range(num_experiments))\n",
    "stds.append(np.std(errors,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(stds[month-1]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.round(estimates[month-1]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(stds[month-1]*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(np.arange(len(estimates))+1, [x[0] * 100 for x in estimates], yerr=[x[0] * 100 for x in stds], capsize=2, label='DID', color='r',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[1] * 100 for x in estimates], yerr=[x[1] * 100 for x in stds], capsize=2, label='SC', color='g',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.axhline(y=0, color='cyan', linestyle='--', linewidth=1)\n",
    "plt.legend()\n",
    "plt.title('Effect Estimates of Florida Bail Policy on Detention')\n",
    "plt.xlabel('Time Horizon (rebookings within x months)', fontsize=14)\n",
    "plt.ylabel('Effect Estimates', fontsize=14)\n",
    "plt.ylim(-10,15)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig('DID-SC-FL-detention-fixed_window_covariates.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(np.arange(len(estimates))+1, [x[2] * 100 for x in estimates], yerr=[x[2] * 100 for x in stds], capsize=2, label='MC',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[3] * 100 for x in estimates], yerr=[x[3] * 100 for x in stds], capsize=2, label='SDID',color='m',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[4] * 100 for x in estimates], yerr=[x[4] * 100 for x in stds], capsize=2, label='TROP',color='black',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.axhline(y=0, color='cyan', linestyle='--', linewidth=1)\n",
    "plt.legend()\n",
    "plt.title('Effect Estimates of Florida Bail Policy on Pretrial Detention')\n",
    "plt.xlabel('Time Horizon (rebookings within x months)', fontsize=14)\n",
    "plt.ylabel('Effect Estimates', fontsize=14)\n",
    "plt.ylim(-10,15)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig('MC-SDID-TROP-FL-detention-fixed_window_covariates.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(np.arange(len(estimates))+1, [x[0] * 100 for x in estimates], yerr=[x[0] * 100 for x in stds], capsize=2, label='DID', color='r',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[1] * 100 for x in estimates], yerr=[x[1] * 100 for x in stds], capsize=2, label='SC', color='g',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.axhline(y=0, color='cyan', linestyle='--', linewidth=1)\n",
    "plt.legend()\n",
    "plt.title('Effect Estimates of Florida Bail Policy on Recidivism')\n",
    "plt.xlabel('Time Horizon (rebookings within x months)', fontsize=14)\n",
    "plt.ylabel('Effect Estimates', fontsize=14)\n",
    "plt.ylim(-40,30)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig('DID-SC-FL_recidivism_fixed_window_covariates.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.errorbar(np.arange(len(MC_estimates))+1, MC_estimates, yerr=MC_stds, capsize=2, label='MC',\n",
    "#             capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "# plt.errorbar(np.arange(len(SDID_estimates))+1, SDID_estimates, yerr=SDID_stds, capsize=2, label='SDID',color='m',\n",
    "#             capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "# plt.legend()\n",
    "# plt.title('Effect Estimates of Florida Bail Policy on Recidivism')\n",
    "# plt.xlabel('Time Horizon (month) of Rebookings', fontsize=14)\n",
    "# plt.ylabel('Effect Estimates', fontsize=14)\n",
    "# plt.savefig('MC-SDID-Florida.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(np.arange(len(estimates))+1, [x[2] * 100 for x in estimates], yerr=[x[2] * 100 for x in stds], capsize=2, label='MC',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[3] * 100 for x in estimates], yerr=[x[3] * 100 for x in stds], capsize=2, label='SDID',color='m',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.errorbar(np.arange(len(estimates))+1, [x[4] * 100 for x in estimates], yerr=[x[4] * 100 for x in stds], capsize=2, label='TROP',color='black',\n",
    "            capthick=2, elinewidth=1.5, marker='s', markerfacecolor='green', markeredgewidth=2)\n",
    "plt.axhline(y=0, color='cyan', linestyle='--', linewidth=1)\n",
    "plt.legend()\n",
    "plt.title('Effect Estimates of Florida Bail Policy on Recidivism')\n",
    "plt.xlabel('Time Horizon (rebookings within x months)', fontsize=14)\n",
    "plt.ylabel('Effect Estimates', fontsize=14)\n",
    "plt.ylim(-40,30)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig('MC-SDID-TROP-FL_recidivism_fixed_window_covariates.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit rank 4 factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_Y(Y,rank=4):\n",
    "    N, T = Y.shape\n",
    "\n",
    "    u,s,v = np.linalg.svd(Y)\n",
    "    factor_unit = u[:,:rank]\n",
    "    factor_time = v[:rank,:]\n",
    "    L = np.dot(factor_unit*s[:rank],factor_time)\n",
    "    E = Y - L\n",
    "    F = np.add.outer(np.mean(L,axis=1),np.mean(L,axis=0)) - np.mean(L)\n",
    "    M = L-F\n",
    "    \n",
    "    return F, M, E, factor_unit*np.sqrt(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit AR(2) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ar2(E):\n",
    "    \n",
    "    T_full = E.shape[1]\n",
    "    E_ts = E[:, 2:]\n",
    "    E_lag_1 = E[:, 1:-1]\n",
    "    E_lag_2 = E[:,:-2]\n",
    "    \n",
    "    a_1 = np.sum(np.diag(np.matmul(E_lag_1, E_lag_1.T)))\n",
    "    a_2 = np.sum(np.diag(np.matmul(E_lag_2, E_lag_2.T)))\n",
    "    a_3 = np.sum(np.diag(np.matmul(E_lag_1, E_lag_2.T)))\n",
    "    \n",
    "    matrix_factor = np.array([[a_1, a_3], \n",
    "                         [a_3, a_2]])\n",
    "    \n",
    "    b_1 = np.sum(np.diag(np.matmul(E_lag_1, E_ts.T)))\n",
    "    b_2 = np.sum(np.diag(np.matmul(E_lag_2, E_ts.T)))\n",
    "    \n",
    "    ar_coef = np.linalg.inv(matrix_factor).dot(np.array([b_1, b_2]))\n",
    "\n",
    "    return ar_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar2_correlation_matrix(ar_coef, T):\n",
    "    \n",
    "    result = np.zeros(T)\n",
    "    result[0] = 1\n",
    "    result[1] = ar_coef[0] / (1 - ar_coef[1])\n",
    "    for t in range(2, T):\n",
    "        result[t] = ar_coef[0] * result[t-1] + ar_coef[1] * result[t-2]\n",
    "    \n",
    "    index_matrix = np.abs(np.arange(T)[:, None] - np.arange(T))\n",
    "    cor_matrix = result[index_matrix].reshape(T, T)\n",
    "    \n",
    "    return cor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, M, E, unit_factors = decompose_Y(Y_true,rank=4)\n",
    "\n",
    "ar_coef = fit_ar2(E)\n",
    "\n",
    "cor_matrix = ar2_correlation_matrix(ar_coef, T_total)\n",
    "\n",
    "scaled_sd = np.linalg.norm(E.T.dot(E)/N_total,ord='fro')/np.linalg.norm(cor_matrix,ord='fro')\n",
    "\n",
    "cov_mat = cor_matrix*scaled_sd\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(penalty=None).fit(unit_factors, assignment_vector)\n",
    "# pi = model.predict_proba(unit_factors)[:,1]\n",
    "\n",
    "print(np.linalg.norm(F,ord='fro')/np.sqrt(N_total*T_total))\n",
    "\n",
    "print(np.linalg.norm(M,ord='fro')/np.sqrt(N_total*T_total))\n",
    "\n",
    "print(np.sqrt(np.trace(cov_mat)/T_total))\n",
    "\n",
    "print(ar_coef)\n",
    "\n",
    "cond_var = cov_mat[-1,-1] - (cov_mat[-1,-3:-1].dot(np.linalg.inv(cov_mat[-3:-1,-3:-1]))).dot(cov_mat[-3:-1,-1])\n",
    "\n",
    "print(np.sqrt(cond_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(F+M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(F, M, cov_mat, treated_periods = 2):\n",
    "    \n",
    "    N, T_total = F.shape\n",
    "    \n",
    "    #Y = F+M\n",
    "    Y =  F+ M + np.random.multivariate_normal(mean = np.zeros((T_total,)), cov = cov_mat, size=N)\n",
    "    \n",
    "    W = np.zeros((N,T_total))\n",
    "    \n",
    "    index = np.array([np.random.choice(N)])\n",
    "            \n",
    "    W[index,-treated_periods:] = 1\n",
    "                        \n",
    "    return Y, W, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_data(F, M, cov_mat, pi, treated_periods = 2, treated_units = 1):\n",
    "    \n",
    "#     N, T_total = F.shape\n",
    "    \n",
    "#     #Y = F+M\n",
    "#     Y =  F+ M + np.random.multivariate_normal(mean = np.zeros((T_total,)), cov = cov_mat, size=N)\n",
    "    \n",
    "#     W = np.zeros((N,T_total))\n",
    "    \n",
    "#     candidates = np.random.binomial(n=1,p=pi)\n",
    "    \n",
    "#     treated_number = np.sum(candidates)\n",
    "\n",
    "#     if treated_number == 0:\n",
    "#         index = np.array(np.random.choice(N))\n",
    "        \n",
    "#     else:\n",
    "#         index = np.squeeze(np.argwhere(candidates==1))      \n",
    "#         if treated_number > treated_units:\n",
    "#             index = np.random.choice(index, size=treated_units, replace=False)\n",
    "\n",
    "#     #index = np.random.choice(np.arange(N_total),size=treated_units, replace=False)\n",
    "            \n",
    "#     W[index,-treated_periods:] = 1\n",
    "                        \n",
    "#     return Y, W, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_actual_treated_unit(F, M, cov_mat, treated_unit, treated_periods=2):\n",
    "    \n",
    "    N, T_total = F.shape\n",
    "    \n",
    "    Y = F + M + np.random.multivariate_normal(mean = np.zeros((T_total,)), cov = cov_mat, size=N)\n",
    "    \n",
    "    #Y /= np.std(Y)\n",
    "    #Y -= np.mean(Y)\n",
    "    \n",
    "    W = np.zeros((N,T_total))\n",
    "    \n",
    "    #candidates = np.random.binomial(n=1,p=pi)\n",
    "            \n",
    "    candidate = treated_unit\n",
    "    #print(candidate)\n",
    "  \n",
    "    W[candidate,-treated_periods:] = 1\n",
    "                        \n",
    "    return Y, W, np.array([candidate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recidivism 6 months (6.4,0.15,0.021)\n",
    "#recidivism 12 months (0,0.75,0.021)\n",
    "#recidivism 15 months (0.75,0.25,0.021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors_sdid = []\n",
    "errors_dwcp = []\n",
    "errors_mc = []\n",
    "errors_sc = []\n",
    "errors_difp = []\n",
    "errors_did = []\n",
    "\n",
    "t_treat = T_total-13\n",
    "\n",
    "for experiment in range(1000):\n",
    "        \n",
    "    np.random.seed(experiment)\n",
    "\n",
    "    Y_test, W_test, treated_units = generate_data(F, M, cov_mat, treated_periods=t_treat)\n",
    "    #Y_test, W_test, treated_units = generate_data_actual_treated_unit(F, M, cov_mat, treated_unit=0)\n",
    "\n",
    "    print('experiment', experiment, 'treated units', treated_units)\n",
    "\n",
    "    # DID \n",
    "    estimate = DID_TWFE(Y_test,W_test)                                               \n",
    "    errors_did.append(estimate)\n",
    "    \n",
    "    # SC\n",
    "    estimate = SC_TWFE(Y_test,W_test,treated_units, treated_periods=t_treat)\n",
    "    errors_sc.append(estimate)\n",
    "    \n",
    "    # MC\n",
    "    estimate = TROP_TWFE_average(Y_test,W_test,treated_units,lambda_unit=0,lambda_time=0,lambda_nn=0.085)\n",
    "    errors_mc.append(estimate)\n",
    "\n",
    "    # SDID\n",
    "    estimate = SDID_TWFE(Y_test, W_test, treated_units,treated_periods=t_treat)\n",
    "    errors_sdid.append(estimate)\n",
    "\n",
    "    # DWCP 2.25,0.05,0.065 9,0.25,0.065 10,0.15,0.085\n",
    "    estimate = TROP_TWFE_average(Y_test,W_test,treated_units,lambda_unit=9,lambda_time=0.25,lambda_nn=0.065)\n",
    "    errors_dwcp.append(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('SDID: ', np.sqrt(np.mean(np.square(errors_sdid))),'DWCP: ',\n",
    "      np.sqrt(np.mean(np.square(errors_dwcp))), 'MC: ', np.sqrt(np.mean(np.square(errors_mc))),\n",
    "      '|SC: ', np.sqrt(np.mean(np.square(errors_sc))), 'DID: ', np.sqrt(np.mean(np.square(errors_did))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('SDID: ', (np.mean((errors_sdid))),'DWCP: ',\n",
    "      (np.mean((errors_dwcp))), 'MC: ', (np.mean((errors_mc))),\n",
    "      '|SC: ', (np.mean((errors_sc))), 'DID: ', (np.mean((errors_did))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
